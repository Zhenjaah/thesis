{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import pprint\n",
    "import fastText\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from bs4 import BeautifulSoup\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parts for data preparation; not used eventually\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words(\"dutch\")\n",
    "#         tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split()) # remove hastags and mentions\n",
    "#         tweet = ' '.join(re.sub(\"[\\'\\.\\,\\!\\?\\:\\;\\-\\=\\(\\)\\[\\]\\{\\}\\\\\\<\\>\\/\\?\\@\\#$#\\%\\^\\&\\*\\_\\~\\\"]\", \" \", tweet).split()) # remove punctuation\n",
    "#         tweet = remove_emoji(tweet)\n",
    "#     df[\"cleaned\"] = df[\"cleaned\"].str.split()\n",
    "#     df[\"cleaned\"].apply(lambda x: [item for item in x if item not in stop_words]) # remove stopwords\n",
    "#     df[\"cleaned\"] = [\" \".join(x) for x in df[\"cleaned\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df[\"cleaned\"] = \"\"\n",
    "    processed_text = []\n",
    "    for text in df[\"text\"]:\n",
    "        text = BeautifulSoup(text).get_text() # transforms things like &amp to &\n",
    "        text = text.lower()\n",
    "        text = ' '.join(re.sub(\"(?<=@)\\w+\", \"MENTION\", text).split()) # replace mentions with \"MENTION\" in tweets\n",
    "        text = ' '.join(re.sub(\"(\\/u\\/[A-Za-z0-9]+)\", \"MENTION\", text).split()) # replace mentions with \"MENTION\" in Reddit Comments. Example: /u/username\n",
    "        text = ' '.join(re.sub(\"(u\\/[A-Za-z0-9]+)\", \"MENTION\", text).split()) # replace mentions with \"MENTION\" in Reddit Comments. Example: u/username\n",
    "        text = ' '.join(re.sub(\"#\", \" \", text).split()) # remove # symbols    \n",
    "        text = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \"URL\", text).split()) # replace links/URLs with \"URL\"\n",
    "        processed_text.append(text)\n",
    "         \n",
    "    df[\"cleaned\"] = processed_text\n",
    "\n",
    "    return df[\"cleaned\"]\n",
    "\n",
    "def replacer(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t', encoding=\"utf8\")\n",
    "    df[\"cleaned\"] = preprocess(df) # add processed text to a new column \"cleaned\" and add this to the dataframe\n",
    "    \n",
    "    # replace all EXPLICIT and IMPLICIT labels with OFFENSIVE\n",
    "    df[\"explicitness\"] = df[\"explicitness\"].replace([\"EXPLICIT\", \"IMPLICIT\"], \"OFFENSIVE\")\n",
    "\n",
    "    print(df[\"explicitness\"].value_counts())\n",
    "    \n",
    "    # transform labels with LabelEncoder\n",
    "    # 0 = NOT\n",
    "    # 1 = OFFENSIVE\n",
    "    df[\"explicitness\"] = df[\"explicitness\"].astype(str)\n",
    "    df[\"explicitness\"] = LabelEncoder().fit_transform(df[\"explicitness\"])\n",
    "\n",
    "    return df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "NOT          5176\n",
      "OFFENSIVE    2588\n",
      "Name: explicitness, dtype: int64\n",
      "Dev:\n",
      "NOT          361\n",
      "OFFENSIVE    186\n",
      "Name: explicitness, dtype: int64\n",
      "Test:\n",
      "NOT          2072\n",
      "OFFENSIVE    1036\n",
      "Name: explicitness, dtype: int64\n",
      "0    @StuiverAnne @LodewijkA Iets anders, wanneer w...\n",
      "1    @GUnight fucking schaamteloos! Je kunt de Afri...\n",
      "2    Mijn hemel! De elite, diegenen die onze cultuu...\n",
      "3    het feit dat mensen nog steeds zwarte piet sup...\n",
      "4    @GerardKrolNL @groenlinks het is goed te zien ...\n",
      "Name: text, dtype: object\n",
      "0    @MENTION @MENTION iets anders, wanneer word as...\n",
      "1    @MENTION fucking schaamteloos! je kunt de afri...\n",
      "2    mijn hemel! de elite, diegenen die onze cultuu...\n",
      "3    het feit dat mensen nog steeds zwarte piet sup...\n",
      "4    @MENTION @MENTION het is goed te zien dat grli...\n",
      "Name: cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "train_df = replacer(\"train_final.csv\")\n",
    "\n",
    "print(\"Dev:\")\n",
    "dev_df = replacer(\"dev_final.csv\")\n",
    "\n",
    "print(\"Test:\")\n",
    "test_df = replacer(\"test_final.csv\")\n",
    "\n",
    "print(train_df[\"text\"].head())\n",
    "print(train_df[\"cleaned\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7764, 20385)\n",
      "(3108, 20385)\n"
     ]
    }
   ],
   "source": [
    "# vectorize words using tf_idf for SVM\n",
    "tf_idf = TfidfVectorizer()\n",
    "# print(tf_idf.get_feature_names())\n",
    "X_train = pd.DataFrame(tf_idf.fit_transform(train_df[\"cleaned\"]).toarray())\n",
    "\n",
    "tf_idf2 = TfidfVectorizer(vocabulary = tf_idf.get_feature_names())\n",
    "X_test = pd.DataFrame(tf_idf2.fit_transform(test_df[\"cleaned\"]).toarray())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy: 0.81\n",
      "SVC macro f1-score: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      2072\n",
      "           1       0.79      0.59      0.68      1036\n",
      "\n",
      "    accuracy                           0.81      3108\n",
      "   macro avg       0.80      0.76      0.77      3108\n",
      "weighted avg       0.81      0.81      0.80      3108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "y_train = train_df[\"explicitness\"].copy()\n",
    "\n",
    "y_test = test_df[\"explicitness\"].copy()\n",
    "\n",
    "model = svm.LinearSVC(loss=\"hinge\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"SVC accuracy: {model.score(X_test, y_test):.2f}\") # 0.8104890604890604\n",
    "\n",
    "SVC_f1 = f1_score(y_test, model.predict(X_test), average='macro') # 0.7706758379027286\n",
    "print(f\"SVC macro f1-score: {SVC_f1:.2f}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paramaters used for the LinearSVC model are:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': True,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The paramaters used for the LinearSVC model are:\\n\")\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1907  165]\n",
      " [ 424  612]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_target = y_test\n",
    "y_predicted = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_target=y_target, \n",
    "                      y_predicted=y_predicted)\n",
    "print(cm)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add prefix to work with fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(dataframe, output_file):\n",
    "\n",
    "    f_rows = []\n",
    "\n",
    "    # add required prefix for fasttext\n",
    "    for index, row in dataframe.iterrows():\n",
    "        fasttext_row = f\"{'__label__' + str(row['explicitness'])} {row['cleaned']}\"\n",
    "        f_rows.append(fasttext_row)\n",
    "        \n",
    "    fasttext_df = pd.DataFrame(f_rows)\n",
    "    \n",
    "    return fasttext_df.to_csv(output_file, index=False, header=False, encoding=\"utf-8\", \n",
    "                              quoting = csv.QUOTE_NONE, quotechar = \"\", escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding prefixes to data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding prefixes to data...\")\n",
    "fasttext_df_train = add_prefix(train_df, 'train.txt')\n",
    "fasttext_df_dev = add_prefix(dev_df, 'dev.txt')\n",
    "fasttext_df_test = add_prefix(test_df, 'test.txt')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train fastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fasttext model...\n",
      "Model loaded succesfully!\n",
      "The paramaters used for the fastText model are:\n",
      "\n",
      "autotuneDuration -> 300\n",
      "autotuneMetric -> f1\n",
      "autotuneModelSize -> \n",
      "autotunePredictions -> 1\n",
      "autotuneValidationFile -> \n",
      "bucket -> 3869285\n",
      "cutoff -> 0\n",
      "dim -> 199\n",
      "dsub -> 2\n",
      "epoch -> 9\n",
      "input -> \n",
      "label -> __label__\n",
      "loss -> loss_name.softmax\n",
      "lr -> 0.05\n",
      "lrUpdateRate -> 100\n",
      "maxn -> 5\n",
      "minCount -> 1\n",
      "minCountLabel -> 0\n",
      "minn -> 2\n",
      "model -> model_name.supervised\n",
      "neg -> 5\n",
      "output -> \n",
      "pretrainedVectors -> \n",
      "qnorm -> False\n",
      "qout -> False\n",
      "retrain -> False\n",
      "saveOutput -> False\n",
      "seed -> 0\n",
      "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x0000029B713521F0>>\n",
      "t -> 0.0001\n",
      "thread -> 12\n",
      "verbose -> 2\n",
      "wordNgrams -> 2\n",
      "ws -> 5\n"
     ]
    }
   ],
   "source": [
    "# print(\"Training fasttext model...\")\n",
    "# f_model = fastText.train_supervised(input=\"train.txt\",  \n",
    "#                                     autotuneValidationFile=\"dev.txt\", \n",
    "#                                     autotuneMetric=\"f1:__label__1\", \n",
    "#                                     autotuneDuration=300)\n",
    "# print(\"Done! Saving the model now...\")\n",
    "# f_model.save_model(\"fasttext_model_binary.bin\")\n",
    "# print(\"The model is saved as 'fasttext_model_binary.bin'.\")\n",
    "\n",
    "print(\"Loading fasttext model...\")\n",
    "f_model = fastText.load_model(\"fasttext_model_binary.bin\")\n",
    "print(\"Model loaded succesfully!\")\n",
    "\n",
    "# the part below is used to print out the arguments of the autotunoValidation\n",
    "print(\"The paramaters used for the fastText model are:\\n\")\n",
    "args_obj = f_model.f.getArgs()\n",
    "for hparam in dir(args_obj):\n",
    "    if not hparam.startswith('__'):\n",
    "        print(f\"{hparam} -> {getattr(args_obj, hparam)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999803900718689, 'halalsema'),\n",
       " (0.9999688863754272, 'gorelinksehalsema'),\n",
       " (0.9999602437019348, 'femkehalsema'),\n",
       " (0.999958872795105, 'halsema!'),\n",
       " (0.9999585151672363, 'halsemaout'),\n",
       " (0.9999548196792603, 'shit'),\n",
       " (0.9999511241912842, 'shit.'),\n",
       " (0.9999502897262573, 'halalsema!'),\n",
       " (0.9999496340751648, 'idioot!'),\n",
       " (0.9999493956565857, 'tuig')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model.get_nearest_neighbors(\"halsema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__1',), array([1.00000942]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all labels (k=-1) with probability higher or equal to 0.5 (threshold)\n",
    "# probabilities such as 1.00000942 occur due to rounding, so these can be seen as 1.0 or 100%\n",
    "test_sentence = \"wij zijn een stel idioten\"\n",
    "f_model.predict(test_sentence,  k=-1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per label:\n",
      "{'__label__0': {'f1score': 0.8587270973963356,\n",
      "                'precision': 0.8578998073217726,\n",
      "                'recall': 0.8595559845559846},\n",
      " '__label__1': {'f1score': 0.7166344294003868,\n",
      "                'precision': 0.7180232558139535,\n",
      "                'recall': 0.7152509652509652}}\n"
     ]
    }
   ],
   "source": [
    "# __label__0 = NOT\n",
    "# __label__1 = OFFENSIVE\n",
    "\n",
    "# The precision is the number of correct labels among the labels predicted by fastText. \n",
    "# The recall is the number of labels that successfully were predicted, among all the real labels.\n",
    "\n",
    "results = f_model.test_label(\"test.txt\")\n",
    "print(\"Results per label:\")\n",
    "pprint.pprint(results)\n",
    "\n",
    "# fastText model trained for 10 minutes\n",
    "# {'__label__0': {'f1score': 0.8690587138863001,\n",
    "#                 'precision': 0.8400900900900901,\n",
    "#                 'recall': 0.900096525096525},\n",
    "#  '__label__1': {'f1score': 0.7079002079002079,\n",
    "#                 'precision': 0.7668918918918919,\n",
    "#                 'recall': 0.6573359073359073}}\n",
    "# fastText model trained for 15 minutes\n",
    "# {'__label__0': {'f1score': 0.8657988165680474,\n",
    "#                 'precision': 0.8495123084068741,\n",
    "#                 'recall': 0.8827220077220077},\n",
    "#  '__label__1': {'f1score': 0.7152184831742843,\n",
    "#                 'precision': 0.7455497382198953,\n",
    "#                 'recall': 0.6872586872586872}}\n",
    "# fastText model trained for 30 minutes\n",
    "# {'__label__0': {'f1score': 0.8638914873713751,\n",
    "#                 'precision': 0.838021778584392,\n",
    "#                 'recall': 0.8914092664092664},\n",
    "#  '__label__1': {'f1score': 0.7,\n",
    "#                 'precision': 0.7511061946902655,\n",
    "#                 'recall': 0.6554054054054054}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on reddit comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(\"reddit_comments.csv\", sep=',', encoding=\"utf8\")\n",
    "\n",
    "preprocess(reddit_df)\n",
    "\n",
    "reddit_df_test = add_prefix(reddit_df, 'reddit_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_model_test(input_file):\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with open(input_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # check the text, ignore label if label == nan\n",
    "            test_sentence = line[14:].rstrip()\n",
    "            predictions.append(f_model.predict(test_sentence,  k=-1, threshold=0.5))\n",
    "\n",
    "    return predictions, test_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT          394\n",
      "OFFENSIVE    131\n",
      "Name: explicitness, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# predict labels with fastText\n",
    "test = fasttext_model_test(\"reddit_test.txt\")\n",
    "\n",
    "# print(reddit_df[\"explicitness\"])\n",
    "# add every predicted label to the dataframe by changing 'NaN' to '__label__X' where X is 0 or 1\n",
    "reddit_df[\"explicitness\"] = [str(label[0])[2:-3] for label in test[0]]\n",
    "# print(reddit_df[\"explicitness\"])\n",
    "\n",
    "# save the labels and processed text to a file to check full output\n",
    "# reddit_df[[\"explicitness\", \"cleaned\"]].to_csv(\"reddit_test_labeled.txt\", index=False, header=False, encoding=\"utf-8\", \n",
    "#                                             quoting = csv.QUOTE_NONE, quotechar = \"\", escapechar = \" \", sep =\" \")\n",
    "\n",
    "reddit_df[\"explicitness\"] = reddit_df[\"explicitness\"].replace([\"__label__1\"], \"OFFENSIVE\")\n",
    "reddit_df[\"explicitness\"] = reddit_df[\"explicitness\"].replace([\"__label__0\"], \"NOT\")\n",
    "\n",
    "# get 25 random samples for both offensive and not offensive predictions\n",
    "NOT_sample_df = reddit_df[reddit_df[\"explicitness\"] == \"NOT\"].sample(n=25, random_state=1)\n",
    "OFFENSIVE_sample_df = reddit_df[reddit_df[\"explicitness\"] == \"OFFENSIVE\"].sample(n=25, random_state=1)\n",
    "\n",
    "reddit_samples_df = pd.concat([NOT_sample_df, OFFENSIVE_sample_df])\n",
    "reddit_samples_df[\"annotation\"] = \"\"\n",
    "\n",
    "reddit_samples_df[[\"explicitness\", \"cleaned\", \"annotation\"]].to_csv(\"reddit_samples.csv\", index=False, encoding=\"utf-8\", sep =\",\")\n",
    "\n",
    "# label distribution after prediction\n",
    "print(reddit_df[\"explicitness\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.60      0.62      0.61        24\n",
      "   OFFENSIVE       0.64      0.62      0.63        26\n",
      "\n",
      "    accuracy                           0.62        50\n",
      "   macro avg       0.62      0.62      0.62        50\n",
      "weighted avg       0.62      0.62      0.62        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotated_reddit_samples_df = pd.read_csv(\"reddit_samples_annotated.csv\", sep=',', encoding=\"utf8\")\n",
    "\n",
    "y_true = annotated_reddit_samples_df[\"annotation\"].copy()\n",
    "y_pred = annotated_reddit_samples_df[\"explicitness\"].copy()\n",
    "\n",
    "print(classification_report(y_true, y_pred, labels=[\"NOT\", \"OFFENSIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  9]\n",
      " [10 16]]\n"
     ]
    }
   ],
   "source": [
    "reddit_cm = confusion_matrix(y_true, y_pred)\n",
    "print(reddit_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate out of vocabulary rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    \"\"\"Used from user saaranshM (https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b)\"\"\"\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def count_number_of_tokens(df):\n",
    "\n",
    "    total_sent_length = []\n",
    "    all_tokens = []\n",
    "\n",
    "    for i, sent in enumerate(df):\n",
    "        # punctuation, emoji's and the words MENTION and URL are removed in the token count\n",
    "        sent = sent.translate(str.maketrans({a: None for a in string.punctuation}))\n",
    "        sent = remove_emoji(sent)\n",
    "        tokens = word_tokenize(sent)\n",
    "        final_tokens = [word for word in tokens if word not in [\"MENTION\", \"URL\"]]\n",
    "        all_tokens += final_tokens\n",
    "        sent_length = len(final_tokens)\n",
    "        total_sent_length.append(sent_length)\n",
    "\n",
    "    unique_tokens = set(all_tokens)\n",
    "    average_number_of_tokens = (sum(total_sent_length)/len(total_sent_length))\n",
    "    \n",
    "    return unique_tokens, average_number_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of all Reddit comments: 69.08\n",
      "Average length of tweets in train data: 19.873905203503348\n",
      "\n",
      "Out of vocabulary rate all Reddit comments: 0.12056136385042855\n",
      "Out of vocabulary rate Reddit comments sample: 0.014834699067533201\n"
     ]
    }
   ],
   "source": [
    "# make word sets for both the twitter train data and reddit data (sample)\n",
    "tok_tweet_train = count_number_of_tokens(train_df[\"cleaned\"])\n",
    "tok_reddit = count_number_of_tokens(reddit_df[\"cleaned\"])\n",
    "tok_reddit_sample = count_number_of_tokens(annotated_reddit_samples_df[\"cleaned\"])\n",
    "\n",
    "reddit_counter = 0\n",
    "reddit_sample_counter = 0\n",
    "\n",
    "# check (lookup) how many tokens from the Reddit data are NOT in the set of the twitter data\n",
    "different_tokens = len(tok_reddit[0].difference(tok_tweet_train[0]))\n",
    "different_tokens_sample = len(tok_reddit_sample[0].difference(tok_tweet_train[0]))\n",
    "        \n",
    "# calculate out of vocabulary rate\n",
    "oov1 = different_tokens/len(tok_tweet_train[0])\n",
    "oov2 = different_tokens_sample/len(tok_tweet_train[0])\n",
    "\n",
    "print(f\"Average length of all Reddit comments: {tok_reddit[1]}\")\n",
    "print(f\"Average length of tweets in train data: {tok_tweet_train[1]}\\n\")\n",
    "\n",
    "print(f\"Out of vocabulary rate all Reddit comments: {oov1}\")\n",
    "print(f\"Out of vocabulary rate Reddit comments sample: {oov2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
