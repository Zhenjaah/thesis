{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import pprint\n",
    "import fastText\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from bs4 import BeautifulSoup\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parts for data preparation; not used eventually\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words(\"dutch\")\n",
    "#         tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split()) # remove hastags and mentions\n",
    "#         tweet = ' '.join(re.sub(\"[\\'\\.\\,\\!\\?\\:\\;\\-\\=\\(\\)\\[\\]\\{\\}\\\\\\<\\>\\/\\?\\@\\#$#\\%\\^\\&\\*\\_\\~\\\"]\", \" \", tweet).split()) # remove punctuation\n",
    "#         tweet = remove_emoji(tweet)\n",
    "#     df[\"cleaned\"] = df[\"cleaned\"].str.split()\n",
    "#     df[\"cleaned\"].apply(lambda x: [item for item in x if item not in stop_words]) # remove stopwords\n",
    "#     df[\"cleaned\"] = [\" \".join(x) for x in df[\"cleaned\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df[\"cleaned\"] = \"\"\n",
    "    processed_text = []\n",
    "    for text in df[\"text\"]:\n",
    "        text = BeautifulSoup(text).get_text() # transforms things like &amp to &\n",
    "        text = text.lower()\n",
    "        text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"MENTION\", text).split()) # replace mentions with \"MENTION\" in tweets\n",
    "        text = ' '.join(re.sub(\"(\\/u\\/[A-Za-z0-9]+)\", \"MENTION\", text).split()) # replace mentions with \"MENTION\" in Reddit Comments. Example: /u/username\n",
    "        text = ' '.join(re.sub(\"(u\\/[A-Za-z0-9]+)\", \"MENTION\", text).split()) # replace mentions with \"MENTION\" in Reddit Comments. Example: u/username\n",
    "        text = ' '.join(re.sub(\"#\", \" \", text).split()) # remove # symbols    \n",
    "        text = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \"URL\", text).split()) # replace links/URLs with \"URL\"\n",
    "        processed_text.append(text)\n",
    "         \n",
    "    df[\"cleaned\"] = processed_text\n",
    "\n",
    "    return df[\"cleaned\"]\n",
    "\n",
    "def replacer(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t', encoding=\"utf8\")\n",
    "    df[\"cleaned\"] = preprocess(df) # add processed text to a new column \"cleaned\" and add this to the dataframe\n",
    "    \n",
    "    # replace all EXPLICIT and IMPLICIT labels with OFFENSIVE\n",
    "    df[\"explicitness\"] = df[\"explicitness\"].replace([\"EXPLICIT\", \"IMPLICIT\"], \"OFFENSIVE\")\n",
    "\n",
    "    print(df[\"explicitness\"].value_counts())\n",
    "    \n",
    "    # transform labels with LabelEncoder\n",
    "    # 0 = NOT\n",
    "    # 1 = OFFENSIVE\n",
    "    df[\"explicitness\"] = df[\"explicitness\"].astype(str)\n",
    "    df[\"explicitness\"] = LabelEncoder().fit_transform(df[\"explicitness\"])\n",
    "\n",
    "    return df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "NOT          5176\n",
      "OFFENSIVE    2588\n",
      "Name: explicitness, dtype: int64\n",
      "Dev:\n",
      "NOT          361\n",
      "OFFENSIVE    186\n",
      "Name: explicitness, dtype: int64\n",
      "Test:\n",
      "NOT          2072\n",
      "OFFENSIVE    1036\n",
      "Name: explicitness, dtype: int64\n",
      "0    @StuiverAnne @LodewijkA Iets anders, wanneer w...\n",
      "1    @GUnight fucking schaamteloos! Je kunt de Afri...\n",
      "2    Mijn hemel! De elite, diegenen die onze cultuu...\n",
      "3    het feit dat mensen nog steeds zwarte piet sup...\n",
      "4    @GerardKrolNL @groenlinks het is goed te zien ...\n",
      "Name: text, dtype: object\n",
      "0    MENTION MENTION iets anders, wanneer word assc...\n",
      "1    MENTION fucking schaamteloos! je kunt de afrik...\n",
      "2    mijn hemel! de elite, diegenen die onze cultuu...\n",
      "3    het feit dat mensen nog steeds zwarte piet sup...\n",
      "4    MENTION MENTION het is goed te zien dat grlink...\n",
      "Name: cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "train_df = replacer(\"train_final.csv\")\n",
    "\n",
    "print(\"Dev:\")\n",
    "dev_df = replacer(\"dev_final.csv\")\n",
    "\n",
    "print(\"Test:\")\n",
    "test_df = replacer(\"test_final.csv\")\n",
    "\n",
    "print(train_df[\"text\"].head())\n",
    "print(train_df[\"cleaned\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7764, 20956)\n",
      "(3108, 20956)\n"
     ]
    }
   ],
   "source": [
    "# vectorize words using tf_idf for SVM\n",
    "tf_idf = TfidfVectorizer()\n",
    "# print(tf_idf.get_feature_names())\n",
    "X_train = pd.DataFrame(tf_idf.fit_transform(train_df[\"cleaned\"]).toarray())\n",
    "\n",
    "tf_idf2 = TfidfVectorizer(vocabulary = tf_idf.get_feature_names())\n",
    "X_test = pd.DataFrame(tf_idf2.fit_transform(test_df[\"cleaned\"]).toarray())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8127413127413128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      2072\n",
      "           1       0.79      0.59      0.68      1036\n",
      "\n",
      "    accuracy                           0.81      3108\n",
      "   macro avg       0.81      0.76      0.77      3108\n",
      "weighted avg       0.81      0.81      0.80      3108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "y_train = train_df[\"explicitness\"].copy()\n",
    "\n",
    "y_test = test_df[\"explicitness\"].copy()\n",
    "\n",
    "model = svm.LinearSVC(loss=\"hinge\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) # 0.8127413127413128\n",
    "\n",
    "f1_score(y_test, model.predict(X_test), average='macro')\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1910  162]\n",
      " [ 420  616]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_target = y_test\n",
    "y_predicted = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_target=y_target, \n",
    "                      y_predicted=y_predicted)\n",
    "print(cm)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add prefix to work with fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(dataframe, output_file):\n",
    "\n",
    "    f_rows = []\n",
    "\n",
    "    # add required prefix for fasttext\n",
    "    for index, row in dataframe.iterrows():\n",
    "        fasttext_row = f\"{'__label__' + str(row['explicitness'])} {row['cleaned']}\"\n",
    "        f_rows.append(fasttext_row)\n",
    "        \n",
    "    fasttext_df = pd.DataFrame(f_rows)\n",
    "    \n",
    "    return fasttext_df.to_csv(output_file, index=False, header=False, encoding=\"utf-8\", \n",
    "                              quoting = csv.QUOTE_NONE, quotechar = \"\", escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding prefixes to data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding prefixes to data...\")\n",
    "fasttext_df_train = add_prefix(train_df, 'train.txt')\n",
    "fasttext_df_dev = add_prefix(dev_df, 'dev.txt')\n",
    "fasttext_df_test = add_prefix(test_df, 'test.txt')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fasttext model...\n",
      "Model loaded succesfully!\n",
      "The paramaters used for the fastText model are:\n",
      "\n",
      "autotuneDuration -> 300\n",
      "autotuneMetric -> f1\n",
      "autotuneModelSize -> \n",
      "autotunePredictions -> 1\n",
      "autotuneValidationFile -> \n",
      "bucket -> 3869285\n",
      "cutoff -> 0\n",
      "dim -> 199\n",
      "dsub -> 2\n",
      "epoch -> 9\n",
      "input -> \n",
      "label -> __label__\n",
      "loss -> loss_name.softmax\n",
      "lr -> 0.05\n",
      "lrUpdateRate -> 100\n",
      "maxn -> 5\n",
      "minCount -> 1\n",
      "minCountLabel -> 0\n",
      "minn -> 2\n",
      "model -> model_name.supervised\n",
      "neg -> 5\n",
      "output -> \n",
      "pretrainedVectors -> \n",
      "qnorm -> False\n",
      "qout -> False\n",
      "retrain -> False\n",
      "saveOutput -> False\n",
      "seed -> 0\n",
      "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x0000029F4E7612F0>>\n",
      "t -> 0.0001\n",
      "thread -> 12\n",
      "verbose -> 2\n",
      "wordNgrams -> 2\n",
      "ws -> 5\n"
     ]
    }
   ],
   "source": [
    "# print(\"Training fasttext model...\")\n",
    "# f_model = fastText.train_supervised(input=\"train.txt\",  \n",
    "#                                     autotuneValidationFile=\"dev.txt\", \n",
    "#                                     autotuneMetric=\"f1:__label__1\", \n",
    "#                                     autotuneDuration=900)\n",
    "# print(\"Done! Saving the model now...\")\n",
    "# f_model.save_model(\"fasttext_model_binary.bin\")\n",
    "# print(\"The model is saved as 'fasttext_model_binary.bin'.\")\n",
    "\n",
    "print(\"Loading fasttext model...\")\n",
    "f_model = fastText.load_model(\"fasttext_model_binary.bin\")\n",
    "print(\"Model loaded succesfully!\")\n",
    "\n",
    "# the part below is used to print out the arguments of the autotunoValidation\n",
    "print(\"The paramaters used for the fastText model are:\\n\")\n",
    "args_obj = f_model.f.getArgs()\n",
    "for hparam in dir(args_obj):\n",
    "    if not hparam.startswith('__'):\n",
    "        print(f\"{hparam} -> {getattr(args_obj, hparam)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999803900718689, 'halalsema'),\n",
       " (0.9999688863754272, 'gorelinksehalsema'),\n",
       " (0.9999602437019348, 'femkehalsema'),\n",
       " (0.999958872795105, 'halsema!'),\n",
       " (0.9999585151672363, 'halsemaout'),\n",
       " (0.9999548196792603, 'shit'),\n",
       " (0.9999511241912842, 'shit.'),\n",
       " (0.9999502897262573, 'halalsema!'),\n",
       " (0.9999496340751648, 'idioot!'),\n",
       " (0.9999493956565857, 'tuig')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model.get_nearest_neighbors(\"halsema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__1',), array([1.00000942]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all labels with probability higher or equal to 0.5\n",
    "test_sentence = \"wij zijn een stel idioten\"\n",
    "f_model.predict(test_sentence,  k=-1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on reddit comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(\"reddit_comments.csv\", sep=',', encoding=\"utf8\")\n",
    "\n",
    "preprocess(reddit_df)\n",
    "\n",
    "reddit_df_test = add_prefix(reddit_df, 'reddit_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_model_test(input_file):\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with open(input_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # check the text, ignore label if label == nan\n",
    "            test_sentence = line[14:].rstrip()\n",
    "            predictions.append(f_model.predict(test_sentence,  k=-1, threshold=0.5))\n",
    "\n",
    "    return predictions, test_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT          394\n",
      "OFFENSIVE    131\n",
      "Name: explicitness, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# predict labels with fastText\n",
    "test = fasttext_model_test(\"reddit_test.txt\")\n",
    "\n",
    "# print(reddit_df[\"explicitness\"])\n",
    "# add every predicted label to the dataframe by changing 'NaN' to '__label__X' where X is 0 or 1\n",
    "reddit_df[\"explicitness\"] = [str(label[0])[2:-3] for label in test[0]]\n",
    "# print(reddit_df[\"explicitness\"])\n",
    "\n",
    "# save the labels and processed text to a file for manual annotation\n",
    "reddit_df[[\"explicitness\", \"cleaned\"]].to_csv(\"reddit_test_labeled.txt\", index=False, header=False, encoding=\"utf-8\", \n",
    "                                              quoting = csv.QUOTE_NONE, quotechar = \"\", escapechar = \" \", sep =\" \")\n",
    "# label distribution after prediction\n",
    "reddit_df[\"explicitness\"] = reddit_df[\"explicitness\"].replace([\"__label__1\"], \"OFFENSIVE\")\n",
    "reddit_df[\"explicitness\"] = reddit_df[\"explicitness\"].replace([\"__label__0\"], \"NOT\")\n",
    "\n",
    "print(reddit_df[\"explicitness\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per label:\n",
      "{'__label__0': {'f1score': 0.8648777012586084,\n",
      "                'precision': 0.8513323983169705,\n",
      "                'recall': 0.8788610038610039},\n",
      " '__label__1': {'f1score': 0.7162094763092269,\n",
      "                'precision': 0.7409700722394221,\n",
      "                'recall': 0.693050193050193}}\n"
     ]
    }
   ],
   "source": [
    "# __label__0 = NOT\n",
    "# __label__1 = OFFENSIVE\n",
    "\n",
    "# The precision is the number of correct labels among the labels predicted by fastText. \n",
    "# The recall is the number of labels that successfully were predicted, among all the real labels.\n",
    "\n",
    "results = f_model.test_label(\"test.txt\")\n",
    "print(\"Results per label:\")\n",
    "pprint.pprint(results)\n",
    "\n",
    "#15\n",
    "# {'__label__0': {'f1score': 0.8648777012586084,\n",
    "#                 'precision': 0.8513323983169705,\n",
    "#                 'recall': 0.8788610038610039},\n",
    "#  '__label__1': {'f1score': 0.7162094763092269,\n",
    "#                 'precision': 0.7409700722394221,\n",
    "#                 'recall': 0.693050193050193}}\n",
    "#30\n",
    "# {'__label__0': {'f1score': 0.8638914873713751,\n",
    "#                 'precision': 0.838021778584392,\n",
    "#                 'recall': 0.8914092664092664},\n",
    "#  '__label__1': {'f1score': 0.7,\n",
    "#                 'precision': 0.7511061946902655,\n",
    "#                 'recall': 0.6554054054054054}}\n",
    "#10\n",
    "# {'__label__0': {'f1score': 0.8690587138863001,\n",
    "#                 'precision': 0.8400900900900901,\n",
    "#                 'recall': 0.900096525096525},\n",
    "#  '__label__1': {'f1score': 0.7079002079002079,\n",
    "#                 'precision': 0.7668918918918919,\n",
    "#                 'recall': 0.6573359073359073}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
