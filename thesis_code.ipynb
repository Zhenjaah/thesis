{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import pprint\n",
    "import fastText\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from bs4 import BeautifulSoup\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parts for data preparation; not used eventually\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words(\"dutch\")\n",
    "#         tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split()) # remove hastags and mentions\n",
    "#         tweet = ' '.join(re.sub(\"[\\'\\.\\,\\!\\?\\:\\;\\-\\=\\(\\)\\[\\]\\{\\}\\\\\\<\\>\\/\\?\\@\\#$#\\%\\^\\&\\*\\_\\~\\\"]\", \" \", tweet).split()) # remove punctuation\n",
    "#         tweet = remove_emoji(tweet)\n",
    "#     df[\"cleaned\"] = df[\"cleaned\"].str.split()\n",
    "#     df[\"cleaned\"].apply(lambda x: [item for item in x if item not in stop_words]) # remove stopwords\n",
    "#     df[\"cleaned\"] = [\" \".join(x) for x in df[\"cleaned\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df[\"cleaned\"] = \"\"\n",
    "    tweets = []\n",
    "    for tweet in df[\"text\"]:\n",
    "        tweet = BeautifulSoup(tweet).get_text() # transforms things like &amp to &\n",
    "        tweet = tweet.lower()\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"MENTION\", tweet).split()) # replace mentions with \"MENTION\"\n",
    "        tweet = ' '.join(re.sub(\"#\", \" \", tweet).split()) # remove # symbols    \n",
    "        tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \"URL\", tweet).split()) # replace links/URLs with \"URL\"\n",
    "        tweets.append(tweet)\n",
    "         \n",
    "    df[\"cleaned\"] = tweets\n",
    "\n",
    "    return df[\"cleaned\"]\n",
    "\n",
    "def replacer(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t', encoding=\"utf8\")\n",
    "    df[\"cleaned\"] = preprocess(df) # add processed text to a new column \"cleaned\" and add this to the dataframe\n",
    "    \n",
    "    # replace all EXPLICIT and IMPLICIT labels with OFFENSIVE\n",
    "    df[\"explicitness\"] = df[\"explicitness\"].replace([\"EXPLICIT\", \"IMPLICIT\"], \"OFFENSIVE\")\n",
    "\n",
    "    print(df[\"explicitness\"].value_counts())\n",
    "    \n",
    "    # transform labels with LabelEncoder\n",
    "    # 0 = NOT\n",
    "    # 1 = OFFENSIVE\n",
    "    df[\"explicitness\"] = df[\"explicitness\"].astype(str)\n",
    "    df[\"explicitness\"] = LabelEncoder().fit_transform(df[\"explicitness\"])\n",
    "\n",
    "    return df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "NOT          5176\n",
      "OFFENSIVE    2588\n",
      "Name: explicitness, dtype: int64\n",
      "Dev:\n",
      "NOT          361\n",
      "OFFENSIVE    186\n",
      "Name: explicitness, dtype: int64\n",
      "Test:\n",
      "NOT          2072\n",
      "OFFENSIVE    1037\n",
      "Name: explicitness, dtype: int64\n",
      "0    @StuiverAnne @LodewijkA Iets anders, wanneer w...\n",
      "1    @GUnight fucking schaamteloos! Je kunt de Afri...\n",
      "2    Mijn hemel! De elite, diegenen die onze cultuu...\n",
      "3    het feit dat mensen nog steeds zwarte piet sup...\n",
      "4    @GerardKrolNL @groenlinks het is goed te zien ...\n",
      "Name: text, dtype: object\n",
      "0    MENTION MENTION iets anders, wanneer word assc...\n",
      "1    MENTION fucking schaamteloos! je kunt de afrik...\n",
      "2    mijn hemel! de elite, diegenen die onze cultuu...\n",
      "3    het feit dat mensen nog steeds zwarte piet sup...\n",
      "4    MENTION MENTION het is goed te zien dat grlink...\n",
      "Name: cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "train_df = replacer(\"https://raw.githubusercontent.com/Zhenjaah/thesis/main/data/train_final.csv\")\n",
    "\n",
    "print(\"Dev:\")\n",
    "dev_df = replacer(\"https://raw.githubusercontent.com/Zhenjaah/thesis/main/data/dev_final.csv\")\n",
    "\n",
    "print(\"Test:\")\n",
    "test_df = replacer(\"https://raw.githubusercontent.com/Zhenjaah/thesis/main/data/test_final.csv\")\n",
    "\n",
    "print(train_df[\"text\"].head())\n",
    "print(train_df[\"cleaned\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7764, 20956)\n",
      "(3109, 20956)\n"
     ]
    }
   ],
   "source": [
    "# vectorize words using tf_idf for SVM\n",
    "tf_idf = TfidfVectorizer()\n",
    "# print(tf_idf.get_feature_names())\n",
    "X_train = pd.DataFrame(tf_idf.fit_transform(train_df[\"cleaned\"]).toarray())\n",
    "\n",
    "tf_idf2 = TfidfVectorizer(vocabulary = tf_idf.get_feature_names())\n",
    "X_test = pd.DataFrame(tf_idf2.fit_transform(test_df[\"cleaned\"]).toarray())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8128015439047925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      2072\n",
      "           1       0.79      0.59      0.68      1037\n",
      "\n",
      "    accuracy                           0.81      3109\n",
      "   macro avg       0.81      0.76      0.77      3109\n",
      "weighted avg       0.81      0.81      0.80      3109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "y_train = train_df[\"explicitness\"].copy()\n",
    "\n",
    "y_test = test_df[\"explicitness\"].copy()\n",
    "\n",
    "model = svm.LinearSVC(loss=\"hinge\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) # 0.8128015439047925\n",
    "\n",
    "f1_score(y_test, model.predict(X_test), average='macro')\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1910  162]\n",
      " [ 420  617]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_target = y_test\n",
    "y_predicted = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_target=y_target, \n",
    "                      y_predicted=y_predicted)\n",
    "print(cm)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add prefix to work with fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(dataframe, output_file):\n",
    "\n",
    "    f_rows = []\n",
    "\n",
    "    # add required prefix for fasttext\n",
    "    for index, row in dataframe.iterrows():\n",
    "        fasttext_row = f\"{'__label__' + str(row['explicitness'])} {row['cleaned']}\"\n",
    "        f_rows.append(fasttext_row)\n",
    "        \n",
    "    fasttext_df = pd.DataFrame(f_rows)\n",
    "    \n",
    "    return fasttext_df.to_csv(output_file, index=False, header=False, encoding=\"utf-8\", \n",
    "                              quoting = csv.QUOTE_NONE, quotechar = \"\", escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding prefixes to data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding prefixes to data...\")\n",
    "fasttext_df_train = add_prefix(train_df, 'train.txt')\n",
    "fasttext_df_dev = add_prefix(dev_df, 'dev.txt')\n",
    "fasttext_df_test = add_prefix(test_df, 'test.txt')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fasttext model...\n",
      "Model loaded succesfully!\n",
      "autotuneDuration -> 300\n",
      "autotuneMetric -> f1\n",
      "autotuneModelSize -> \n",
      "autotunePredictions -> 1\n",
      "autotuneValidationFile -> \n",
      "bucket -> 103348\n",
      "cutoff -> 0\n",
      "dim -> 375\n",
      "dsub -> 2\n",
      "epoch -> 5\n",
      "input -> \n",
      "label -> __label__\n",
      "loss -> loss_name.softmax\n",
      "lr -> 0.05\n",
      "lrUpdateRate -> 100\n",
      "maxn -> 6\n",
      "minCount -> 1\n",
      "minCountLabel -> 0\n",
      "minn -> 3\n",
      "model -> model_name.supervised\n",
      "neg -> 5\n",
      "output -> \n",
      "pretrainedVectors -> \n",
      "qnorm -> False\n",
      "qout -> False\n",
      "retrain -> False\n",
      "saveOutput -> False\n",
      "seed -> 0\n",
      "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x000001ECB4486130>>\n",
      "t -> 0.0001\n",
      "thread -> 12\n",
      "verbose -> 2\n",
      "wordNgrams -> 2\n",
      "ws -> 5\n"
     ]
    }
   ],
   "source": [
    "# print(\"Training fasttext model...\")\n",
    "# f_model = fastText.train_supervised(input=\"train.txt\",  \n",
    "#                                     autotuneValidationFile=\"dev.txt\", \n",
    "#                                     autotuneMetric=\"f1:__label__1\", \n",
    "#                                     autotuneDuration=900)\n",
    "# print(\"Done! Saving the model now...\")\n",
    "# f_model.save_model(\"fasttext_model_binary.bin\")\n",
    "# print(\"The model is saved as 'fasttext_model_binary.bin'.\")\n",
    "\n",
    "print(\"Loading fasttext model...\")\n",
    "f_model = fastText.load_model(\"fasttext_model_binary.bin\")\n",
    "print(\"Model loaded succesfully!\")\n",
    "\n",
    "# the part below is used to print out the arguments of the autotunoValidation\n",
    "args_obj = f_model.f.getArgs()\n",
    "for hparam in dir(args_obj):\n",
    "    if not hparam.startswith('__'):\n",
    "        print(f\"{hparam} -> {getattr(args_obj, hparam)}\")\n",
    "        \n",
    "# f_model_tuned = fastText.train_supervised(input=\"train.txt\", \n",
    "#                                          bucket=103348,\n",
    "#                                          dim=375,\n",
    "#                                          epoch=5,\n",
    "#                                          label='__label__',\n",
    "#                                          loss='softmax',\n",
    "#                                          lr = 0.05,\n",
    "#                                          lrUpdateRate=100,\n",
    "#                                          maxn=6,\n",
    "#                                          minCount=1,\n",
    "#                                          minn=3,\n",
    "#                                          neg=5,\n",
    "#                                          thread=12,\n",
    "#                                          seed=0,\n",
    "#                                          t=0.0001,\n",
    "#                                          verbose=2,\n",
    "#                                          wordNgrams=2,\n",
    "#                                          ws=5)\n",
    "# f_model_tuned.save_model(\"fasttext_model_binary_tuned.bin\")\n",
    "# print(\"The model is saved as 'fasttext_model_binary_tuned.bin'.\")\n",
    "\n",
    "# f_model_tuned = fastText.load_model(\"fasttext_model_binary_tuned.bin\")\n",
    "# print(\"Model loaded succesfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999922513961792, 'halalsema'),\n",
       " (0.9999881982803345, 'gorelinksehalsema'),\n",
       " (0.9999875426292419, 'femkehalsema'),\n",
       " (0.9999857544898987, 'halsema!'),\n",
       " (0.9999817609786987, 'halsema:'),\n",
       " (0.9999811053276062, 'neger'),\n",
       " (0.9999808669090271, 'domme'),\n",
       " (0.9999808073043823, 'shit'),\n",
       " (0.9999802112579346, 'halalsema!'),\n",
       " (0.9999796152114868, 'idioot')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model.get_nearest_neighbors(\"halsema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__1',), array([1.00001001]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all labels with probability higher or equal to 0.5\n",
    "test_sentence = \"wij zijn een stel idioten\"\n",
    "f_model.predict(test_sentence,  k=-1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on reddit comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(\"reddit_comments.csv\", sep=',', encoding=\"utf8\")\n",
    "\n",
    "preprocess(reddit_df)\n",
    "\n",
    "reddit_df_test = add_prefix(reddit_df, 'reddit_test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_model_test(input_file):\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with open(input_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # check the text, ignore label if label == nan\n",
    "            test_sentence = line[14:].rstrip()\n",
    "            predictions.append(f_model.predict(test_sentence,  k=-1, threshold=0.5))\n",
    "\n",
    "    return predictions, test_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      OFFENSIVE\n",
      "1      OFFENSIVE\n",
      "2            NOT\n",
      "3      OFFENSIVE\n",
      "4            NOT\n",
      "         ...    \n",
      "520          NOT\n",
      "521          NOT\n",
      "522          NOT\n",
      "523          NOT\n",
      "524          NOT\n",
      "Name: explicitness, Length: 525, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test = fasttext_model_test(\"reddit_test_data.txt\")\n",
    "\n",
    "reddit_df[\"explicitness\"] = [str(label[0])[2:-3] for label in test[0]]\n",
    "reddit_df[[\"explicitness\", \"text\"]].to_csv(\"reddit_test_with_labels.txt\", index=False, header=False, encoding=\"utf-8\", \n",
    "                              quoting = csv.QUOTE_NONE, quotechar = \"\", escapechar = \" \", sep =\" \")\n",
    "reddit_df[\"explicitness\"] = reddit_df[\"explicitness\"].replace([\"__label__1\"], \"OFFENSIVE\")\n",
    "reddit_df[\"explicitness\"] = reddit_df[\"explicitness\"].replace([\"__label__0\"], \"NOT\")\n",
    "\n",
    "print(reddit_df[\"explicitness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per label:\n",
      "{'__label__0': {'f1score': 0.8692994828396803,\n",
      "                'precision': 0.8473877176901925,\n",
      "                'recall': 0.8923745173745173},\n",
      " '__label__1': {'f1score': 0.7169042769857433,\n",
      "                'precision': 0.7594390507011867,\n",
      "                'recall': 0.6788813886210222}}\n"
     ]
    }
   ],
   "source": [
    "# __label__0 = NOT\n",
    "# __label__1 = OFFENSIVE\n",
    "\n",
    "# The precision is the number of correct labels among the labels predicted by fastText. \n",
    "# The recall is the number of labels that successfully were predicted, among all the real labels.\n",
    "\n",
    "results = f_model.test_label(\"test.txt\")\n",
    "print(\"Results per label:\")\n",
    "pprint.pprint(results)\n",
    "\n",
    "# {'__label__0': {'f1score': 0.8692994828396803,\n",
    "#                 'precision': 0.8473877176901925,\n",
    "#                 'recall': 0.8923745173745173},\n",
    "#  '__label__1': {'f1score': 0.7166156982670744,\n",
    "#                 'precision': 0.7591792656587473,\n",
    "#                 'recall': 0.6785714285714286}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
